{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61d021bafd01e399",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This is the file you use when you want to input tweets into the database from csvs.\n",
    "running this code will wipe everything you had and put fresh stuff in there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T12:45:29.135047Z",
     "start_time": "2024-07-25T12:45:26.615671Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d17db008b5ea09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T12:45:29.136383Z",
     "start_time": "2024-07-25T12:45:29.133393Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total = 0\n",
    "data_frames = []\n",
    "directory_path = './Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79b78adb27e2c5c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T12:45:29.139840Z",
     "start_time": "2024-07-25T12:45:29.135918Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date_format = \"%Y-%m-%d\"\n",
    "\n",
    "def convert_to_datetime(date_str):\n",
    "    try:\n",
    "        return datetime.strptime(date_str, date_format)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error converting date: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95c3d8c370bbf02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T12:49:24.694614Z",
     "start_time": "2024-07-25T12:49:24.632907Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      2018-01-03\n",
      "1      2018-01-04\n",
      "2      2018-01-19\n",
      "3      2018-03-15\n",
      "4      2018-03-15\n",
      "          ...    \n",
      "6151   2022-12-29\n",
      "6152   2022-12-30\n",
      "6153   2022-12-30\n",
      "6154   2022-12-30\n",
      "6155   2022-12-31\n",
      "Name: time, Length: 6156, dtype: datetime64[ns]\n",
      "HOW MUCH I GOT FROM  ./Data/RedTide_Manatee_all_SIMPLE_columns.csv 6156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rn/lqtdghhn4t520ncdgvwhvd4c0000gn/T/ipykernel_75453/3028234034.py:6: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       2018-01-26\n",
      "1       2018-02-12\n",
      "2       2018-02-16\n",
      "3       2018-03-25\n",
      "4       2018-04-27\n",
      "           ...    \n",
      "26304   2022-12-31\n",
      "26305   2022-12-31\n",
      "26306   2022-12-31\n",
      "26307   2022-12-31\n",
      "26308   2023-01-29\n",
      "Name: time, Length: 26309, dtype: datetime64[ns]\n",
      "HOW MUCH I GOT FROM  ./Data/RedTide_Tampa_all_SIMPLE_columns.csv 26309\n",
      "ISSUE WITH THE FOLLOWING FILE: ALL_RECENT_SEARCH_RedTide_Pasco_all_SIMPLE_columns.csv\n",
      "\"None of [Index(['text_with_display_links', 'username', 'created_at.x',\\n       'profile_image_url', 'location', 'id', 'public_metrics.x_retweet_count',\\n       'public_metrics.x_reply_count', 'public_metrics.x_like_count'],\\n      dtype='object')] are in the [columns]\"\n",
      "0    2024-09-05\n",
      "1    2024-06-23\n",
      "2    2024-04-28\n",
      "3    2024-04-25\n",
      "4    2024-04-08\n",
      "5    2024-04-08\n",
      "6    2024-04-08\n",
      "7    2024-04-08\n",
      "8    2024-04-08\n",
      "9    2024-04-08\n",
      "10   2024-04-08\n",
      "11   2024-03-26\n",
      "12   2024-03-20\n",
      "13   2024-03-01\n",
      "14   2024-02-28\n",
      "15   2024-02-07\n",
      "16   2024-01-11\n",
      "17   2023-09-25\n",
      "18   2023-09-19\n",
      "19   2023-08-21\n",
      "20   2023-08-21\n",
      "21   2023-08-06\n",
      "Name: time, dtype: datetime64[ns]\n",
      "HOW MUCH I GOT FROM  ./Data/ALL_RECENT_SEARCH_RedTide_Pinellas.StPete_all_SIMPLE_columns.csv 22\n",
      "0    2024-07-11\n",
      "1    2024-07-11\n",
      "2    2024-07-10\n",
      "3    2024-07-10\n",
      "4    2024-07-10\n",
      "5    2024-07-10\n",
      "6    2024-07-10\n",
      "7    2024-07-10\n",
      "8    2024-07-10\n",
      "9    2024-07-10\n",
      "10   2024-07-10\n",
      "11   2024-07-10\n",
      "12   2024-07-10\n",
      "13   2024-07-10\n",
      "14   2024-07-10\n",
      "15   2024-07-10\n",
      "16   2024-07-10\n",
      "17   2024-07-10\n",
      "18   2024-07-10\n",
      "19   2024-07-10\n",
      "20   2024-07-10\n",
      "21   2024-07-10\n",
      "22   2024-07-09\n",
      "23   2024-07-09\n",
      "24   2024-07-09\n",
      "25   2024-07-09\n",
      "26   2024-07-09\n",
      "27   2024-07-09\n",
      "28   2024-07-09\n",
      "29   2024-07-09\n",
      "30   2024-07-09\n",
      "31   2024-07-09\n",
      "32   2024-07-09\n",
      "33   2024-07-09\n",
      "34   2024-07-09\n",
      "35   2024-07-09\n",
      "36   2024-07-09\n",
      "37   2024-07-09\n",
      "38   2024-03-04\n",
      "39   2024-03-03\n",
      "40   2024-02-10\n",
      "41   2024-01-30\n",
      "42   2024-01-29\n",
      "43   2024-01-29\n",
      "44   2024-01-29\n",
      "45   2024-01-29\n",
      "46   2023-10-20\n",
      "47   2023-10-19\n",
      "48   2023-08-25\n",
      "49   2023-08-24\n",
      "50   2023-08-24\n",
      "51   2023-08-21\n",
      "Name: time, dtype: datetime64[ns]\n",
      "HOW MUCH I GOT FROM  ./Data/ALL_RECENT_SEARCH_RedTide_Manatee_all_SIMPLE_columns.csv 52\n",
      "0      2018-01-05\n",
      "1      2018-01-13\n",
      "2      2018-03-25\n",
      "3      2018-05-13\n",
      "4      2018-06-14\n",
      "          ...    \n",
      "8581   2022-12-21\n",
      "8582   2022-12-24\n",
      "8583   2022-12-25\n",
      "8584   2022-12-25\n",
      "8585   2022-12-25\n",
      "Name: time, Length: 8586, dtype: datetime64[ns]\n",
      "HOW MUCH I GOT FROM  ./Data/RedTide_Pinellas.StPete_all_SIMPLE_columns.csv 8586\n",
      "0     2024-09-25\n",
      "1     2024-09-24\n",
      "2     2024-09-24\n",
      "3     2024-09-19\n",
      "4     2024-08-25\n",
      "         ...    \n",
      "469   2023-07-22\n",
      "470   2023-07-22\n",
      "471   2023-07-22\n",
      "472   2023-07-22\n",
      "473   2023-07-22\n",
      "Name: time, Length: 474, dtype: datetime64[ns]\n",
      "HOW MUCH I GOT FROM  ./Data/ALL_RECENT_SEARCH_RedTide_Tampa_all_SIMPLE_columns.csv 474\n",
      "0     2024-09-25\n",
      "1     2024-09-24\n",
      "2     2024-09-24\n",
      "3     2024-09-23\n",
      "4     2024-09-06\n",
      "         ...    \n",
      "118   2023-11-16\n",
      "119   2023-11-15\n",
      "120   2023-11-15\n",
      "121   2023-10-26\n",
      "122   2023-09-23\n",
      "Name: time, Length: 123, dtype: datetime64[ns]\n",
      "HOW MUCH I GOT FROM  ./Data/ALL_RECENT_SEARCH_RedTide_Pinellas.Clearwater_all_SIMPLE_columns.csv 123\n",
      "0     2018-08-16\n",
      "1     2018-08-21\n",
      "2     2018-08-22\n",
      "3     2018-08-22\n",
      "4     2018-08-22\n",
      "         ...    \n",
      "200   2021-10-08\n",
      "201   2021-10-08\n",
      "202   2022-07-07\n",
      "203   2022-07-07\n",
      "204   2022-12-28\n",
      "Name: time, Length: 205, dtype: datetime64[ns]\n",
      "HOW MUCH I GOT FROM  ./Data/RedTide_Pasco_all_SIMPLE_columns.csv 205\n",
      "0     2024-09-25\n",
      "1     2024-09-24\n",
      "2     2024-09-24\n",
      "3     2024-09-24\n",
      "4     2024-09-24\n",
      "         ...    \n",
      "580   2023-07-24\n",
      "581   2023-07-23\n",
      "582   2023-07-22\n",
      "583   2023-07-21\n",
      "584   2023-07-21\n",
      "Name: time, Length: 585, dtype: datetime64[ns]\n",
      "HOW MUCH I GOT FROM  ./Data/ALL_RECENT_SEARCH_RedTide_Sarasota_all_SIMPLE_columns.csv 585\n",
      "0       2018-06-13\n",
      "1       2018-07-02\n",
      "2       2018-07-11\n",
      "3       2018-07-12\n",
      "4       2018-07-20\n",
      "           ...    \n",
      "16347   2022-12-28\n",
      "16348   2022-12-30\n",
      "16349   2022-12-30\n",
      "16350   2022-12-30\n",
      "16351   2022-12-31\n",
      "Name: time, Length: 16352, dtype: datetime64[ns]\n",
      "HOW MUCH I GOT FROM  ./Data/RedTide_Pinellas.Clearwater_all_SIMPLE_columns.csv 16352\n",
      "0       2018-01-01\n",
      "1       2018-01-01\n",
      "2       2018-01-02\n",
      "3       2018-01-02\n",
      "4       2018-01-02\n",
      "           ...    \n",
      "15947   2022-12-30\n",
      "15948   2022-12-30\n",
      "15949   2022-12-31\n",
      "15950   2022-12-31\n",
      "15951   2023-03-18\n",
      "Name: time, Length: 15952, dtype: datetime64[ns]\n",
      "HOW MUCH I GOT FROM  ./Data/RedTide_Sarasota_all_SIMPLE_columns.csv 15952\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        if filename.startswith('RedTide') or (filename.startswith('ALL_RECENT') and 'RedTide' in filename):\n",
    "        #if filename.startswith('ALL_RECENT_SEARCH_RedTide_Pinellas.Clearwater_all_SIMPLE_columns'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            data = pd.read_csv(file_path)\n",
    "    \n",
    "            total = + len(data)\n",
    "            labelled_accounts_df = pd.read_csv(\"Final_Account_Labels_for_Dashboard.csv\")\n",
    "            labelled_accounts_df = labelled_accounts_df[[\"Label\", \"username\"]]\n",
    "            labelled_accounts_df.rename(columns={'Label': 'label'}, inplace=True)\n",
    "            try:\n",
    "                selected_columns = ['text_with_display_links', 'username', 'created_at.x', 'profile_image_url', 'location','id', 'public_metrics.x_retweet_count', 'public_metrics.x_reply_count', 'public_metrics.x_like_count']\n",
    "                data = data[selected_columns]\n",
    "                data.rename(columns={'text_with_display_links':'text','created_at.x': 'time', 'profile_image_url': 'image', 'public_metrics.x_retweet_count':'retweets', 'public_metrics.x_reply_count':'replies', 'public_metrics.x_like_count':'likes'}, inplace=True)\n",
    "                \n",
    "                # Extract date part from the 'time' column\n",
    "                data['time'] = data['time'].str.split(' ').str[0].apply(convert_to_datetime)\n",
    "                print(data['time'])\n",
    " \n",
    "                # Add a column to check if the tweet is a retweet\n",
    "                data['is_retweet'] = data['text'].str.startswith('RT')\n",
    " \n",
    "                county_name = \"Hillsborough\"\n",
    "                # updating the location column with county name\n",
    "                if 'Pasco' in filename:\n",
    "                    data['location'] = 'Pasco'\n",
    "                    county_name = 'Pasco'\n",
    "                elif 'Pinellas' in filename:\n",
    "                    data['location'] = 'Pinellas'\n",
    "                    county_name = 'Pinellas'\n",
    "                elif 'Tampa' in filename:\n",
    "                    data['location'] = 'Hillsborough'\n",
    "                    county_name = 'Hillsborough'\n",
    "                elif 'Manatee' in filename:\n",
    "                    data['location'] = 'Manatee'\n",
    "                    county_name = 'Manatee'\n",
    "                elif 'Sarasota' in filename:\n",
    "                    data['location'] = 'Sarasota'\n",
    "                    county_name = 'Sarasota'\n",
    "    \n",
    "                # TODO: Add an account type column\n",
    "                data = pd.merge(data, labelled_accounts_df, on='username', how='left')\n",
    "                data.fillna('No Label', inplace=True)\n",
    "    \n",
    "                # Take the top 20000 tweets\n",
    "                # top_100_tweets = data.head(20000)\n",
    "                print(\"HOW MUCH I GOT FROM \", file_path, len(data))\n",
    "    \n",
    "                data_frames.append(data)\n",
    "            except Exception as E:\n",
    "                print(\"ISSUE WITH THE FOLLOWING FILE:\", filename)\n",
    "                print(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb690209e089fc59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T17:24:19.156415Z",
     "start_time": "2024-07-23T17:24:19.120514Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "big_data_frame = pd.concat(data_frames, ignore_index=True)\n",
    "# big_data_frame.drop_duplicates(subset='text', keep='first', inplace=True)\n",
    "big_data_frame.drop_duplicates(subset='id', keep='first', inplace=True)\n",
    "big_data_frame = big_data_frame.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1ef4ddc7710ffe6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T17:24:19.230988Z",
     "start_time": "2024-07-23T17:24:19.157448Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "\n",
    "MONGO_URI = \"mongodb+srv://Neffati:y4m4SKKmoIg6riCP@cluster0.h1xa7vw.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
    "connection = pymongo.MongoClient(MONGO_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd81851a10e9e2de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T17:24:19.234136Z",
     "start_time": "2024-07-23T17:24:19.232263Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db = connection.tweets\n",
    "# db[\"all_tweets\"].drop()    # Cleans out everything "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e74dc9b396e6106d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T17:24:34.759058Z",
     "start_time": "2024-07-23T17:24:19.235025Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting Done. Successfully Inserted  64543 Tweets.\n"
     ]
    }
   ],
   "source": [
    "db[\"all_tweets\"].drop()    # Cleans out everything \n",
    "\n",
    "all_tweets = db.all_tweets # Makes a new collection \n",
    "all_tweets.insert_many(big_data_frame.to_dict('records'))\n",
    "\n",
    "print(\"Inserting Done. Successfully Inserted \", len(big_data_frame), \"Tweets.\")\n",
    "\n",
    "# output_csv_path = 'big_data.csv'\n",
    "# big_data_frame.to_csv(output_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78c77ad9d2678fa2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T17:24:34.776612Z",
     "start_time": "2024-07-23T17:24:34.756339Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row with the most recent date:\n",
      "text          RT @weatherbryan: It's a stew of harmful algae...\n",
      "username                                             DocClaireP\n",
      "time                                        2024-09-25 00:00:00\n",
      "image         https://pbs.twimg.com/profile_images/777689054...\n",
      "location                                           Hillsborough\n",
      "id                                          1838741951681585641\n",
      "retweets                                                      2\n",
      "replies                                                       0\n",
      "likes                                                         0\n",
      "is_retweet                                                 True\n",
      "label                                                      acad\n",
      "Name: 46387, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert 'date' column to datetime\n",
    "big_data_frame['time'] = pd.to_datetime(big_data_frame['time'])\n",
    "\n",
    "# Find the row with the most recent date\n",
    "most_recent_row = big_data_frame.loc[big_data_frame['time'].idxmax()]\n",
    "\n",
    "print(\"Row with the most recent date:\")\n",
    "print(most_recent_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f00ebb4b1b0289ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T17:24:34.777201Z",
     "start_time": "2024-07-23T17:24:34.775706Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
