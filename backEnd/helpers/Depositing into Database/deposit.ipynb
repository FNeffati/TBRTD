{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This is the file you use when you want to input tweets into the database from csvs.\n",
    "running this code will wipe everything you had and put fresh stuff in there. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61d021bafd01e399"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-08T00:53:19.911734Z",
     "start_time": "2024-07-08T00:53:19.436202Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "total = 0\n",
    "data_frames = []\n",
    "directory_path = './Data/'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-08T00:53:19.914260Z",
     "start_time": "2024-07-08T00:53:19.912592Z"
    }
   },
   "id": "4d17db008b5ea09"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "date_format = \"%Y-%m-%d\"\n",
    "\n",
    "def convert_to_datetime(date_str):\n",
    "    try:\n",
    "        return datetime.strptime(date_str, date_format)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error converting date: {e}\")\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-08T00:53:19.916668Z",
     "start_time": "2024-07-08T00:53:19.915408Z"
    }
   },
   "id": "79b78adb27e2c5c9"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOW MUCH I GOT FROM  ./Data/RedTide_Manatee_all_SIMPLE_columns.csv 6156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r7/6cts6h556zzgbx26m_g0p4gw0000gn/T/ipykernel_53197/2822042843.py:5: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOW MUCH I GOT FROM  ./Data/RedTide_Tampa_all_SIMPLE_columns.csv 20000\n",
      "HOW MUCH I GOT FROM  ./Data/RedTide_Pinellas.StPete_all_SIMPLE_columns.csv 8586\n",
      "HOW MUCH I GOT FROM  ./Data/RedTide_Pasco_all_SIMPLE_columns.csv 205\n",
      "HOW MUCH I GOT FROM  ./Data/RedTide_Pinellas.Clearwater_all_SIMPLE_columns.csv 16352\n",
      "HOW MUCH I GOT FROM  ./Data/RedTide_Sarasota_all_SIMPLE_columns.csv 15952\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        if filename.startswith('RedTide'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            data = pd.read_csv(file_path)\n",
    "    \n",
    "            total = + len(data)\n",
    "            labelled_accounts_df = pd.read_csv(\"Final_Account_Labels_for_Dashboard.csv\")\n",
    "            labelled_accounts_df = labelled_accounts_df[[\"Label\", \"username\"]]\n",
    "            labelled_accounts_df.rename(columns={'Label': 'label'}, inplace=True)\n",
    "            try:\n",
    "                selected_columns = ['text_with_display_links', 'username', 'created_at.x', 'profile_image_url', 'location','id', 'public_metrics.x_retweet_count', 'public_metrics.x_reply_count', 'public_metrics.x_like_count']\n",
    "                data = data[selected_columns]\n",
    "                data.rename(columns={'text_with_display_links':'text','created_at.x': 'time', 'profile_image_url': 'image', 'public_metrics.x_retweet_count':'retweets', 'public_metrics.x_reply_count':'replies', 'public_metrics.x_like_count':'likes'}, inplace=True)\n",
    "                \n",
    "                # Extract date part from the 'time' column\n",
    "                data['time'] = data['time'].str.split(' ').str[0].apply(convert_to_datetime)\n",
    " \n",
    "                # Add a column to check if the tweet is a retweet\n",
    "                data['is_retweet'] = data['text'].str.startswith('RT')\n",
    " \n",
    "                county_name = \"Hillsborough\"\n",
    "                # updating the location column with county name\n",
    "                if 'Pasco' in filename:\n",
    "                    data['location'] = 'Pasco'\n",
    "                    county_name = 'Pasco'\n",
    "                elif 'Pinellas' in filename:\n",
    "                    data['location'] = 'Pinellas'\n",
    "                    county_name = 'Pinellas'\n",
    "                elif 'Tampa' in filename:\n",
    "                    data['location'] = 'Hillsborough'\n",
    "                    county_name = 'Hillsborough'\n",
    "                elif 'Manatee' in filename:\n",
    "                    data['location'] = 'Manatee'\n",
    "                    county_name = 'Manatee'\n",
    "                elif 'Sarasota' in filename:\n",
    "                    data['location'] = 'Sarasota'\n",
    "                    county_name = 'Sarasota'\n",
    "    \n",
    "                # TODO: Add an account type column\n",
    "                data = pd.merge(data, labelled_accounts_df, on='username', how='left')\n",
    "                data.fillna('No Label', inplace=True)\n",
    "    \n",
    "                # Take the top 20000 tweets\n",
    "                top_100_tweets = data.head(20000)\n",
    "                print(\"HOW MUCH I GOT FROM \", file_path, len(top_100_tweets))\n",
    "    \n",
    "                data_frames.append(top_100_tweets)\n",
    "            except Exception as E:\n",
    "                print(\"ISSUE WITH THE FOLLOWING FILE:\", filename)\n",
    "                print(E)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-08T00:53:21.043617Z",
     "start_time": "2024-07-08T00:53:19.916832Z"
    }
   },
   "id": "95c3d8c370bbf02"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "big_data_frame = pd.concat(data_frames, ignore_index=True)\n",
    "# big_data_frame.drop_duplicates(subset='text', keep='first', inplace=True)\n",
    "big_data_frame.drop_duplicates(subset='id', keep='first', inplace=True)\n",
    "big_data_frame = big_data_frame.sample(frac=1).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-08T00:53:21.065533Z",
     "start_time": "2024-07-08T00:53:21.045837Z"
    }
   },
   "id": "eb690209e089fc59"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import pymongo\n",
    "\n",
    "MONGO_URI = \"mongodb+srv://Neffati:y4m4SKKmoIg6riCP@cluster0.h1xa7vw.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
    "connection = pymongo.MongoClient(MONGO_URI)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-08T00:53:21.113157Z",
     "start_time": "2024-07-08T00:53:21.064444Z"
    }
   },
   "id": "d1ef4ddc7710ffe6"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "db = connection.tweets\n",
    "# db[\"all_tweets\"].drop()    # Cleans out everything "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-08T00:53:21.116467Z",
     "start_time": "2024-07-08T00:53:21.113902Z"
    }
   },
   "id": "fd81851a10e9e2de"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting Done. Successfully Inserted  58534 Tweets.\n"
     ]
    }
   ],
   "source": [
    "db[\"all_tweets\"].drop()    # Cleans out everything \n",
    "\n",
    "all_tweets = db.all_tweets # Makes a new collection \n",
    "all_tweets.insert_many(big_data_frame.to_dict('records'))\n",
    "\n",
    "print(\"Inserting Done. Successfully Inserted \", len(big_data_frame), \"Tweets.\")\n",
    "\n",
    "# output_csv_path = 'big_data.csv'\n",
    "# big_data_frame.to_csv(output_csv_path, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-08T00:53:56.254516Z",
     "start_time": "2024-07-08T00:53:21.117004Z"
    }
   },
   "id": "e74dc9b396e6106d"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-08T00:53:56.255542Z",
     "start_time": "2024-07-08T00:53:56.254823Z"
    }
   },
   "id": "f00ebb4b1b0289ca"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
