{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This is the file you use when you want to input tweets into the database from csvs.\n",
    "running this code will wipe everything you had and put fresh stuff in there. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61d021bafd01e399"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-24T16:51:18.874445Z",
     "start_time": "2024-04-24T16:51:18.870587Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "total = 0\n",
    "data_frames = []\n",
    "directory_path = './Data/'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T16:51:19.332942Z",
     "start_time": "2024-04-24T16:51:19.324353Z"
    }
   },
   "id": "4d17db008b5ea09"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "date_format = \"%Y-%m-%d\"\n",
    "\n",
    "def convert_to_datetime(date_str):\n",
    "    try:\n",
    "        return datetime.strptime(date_str, date_format)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error converting date: {e}\")\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T16:51:19.865833Z",
     "start_time": "2024-04-24T16:51:19.857558Z"
    }
   },
   "id": "79b78adb27e2c5c9"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOW MUCH I GOT FROM  ./Data/RedTide_Manatee_all_SIMPLE_columns.csv 3948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r7/6cts6h556zzgbx26m_g0p4gw0000gn/T/ipykernel_63462/2806639621.py:5: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOW MUCH I GOT FROM  ./Data/RedTide_Tampa_all_SIMPLE_columns.csv 10000\n",
      "HOW MUCH I GOT FROM  ./Data/RedTide_Pinellas.StPete_all_SIMPLE_columns.csv 4479\n",
      "HOW MUCH I GOT FROM  ./Data/RedTide_Pasco_all_SIMPLE_columns.csv 169\n",
      "HOW MUCH I GOT FROM  ./Data/RedTide_Pinellas.Clearwater_all_SIMPLE_columns.csv 6865\n",
      "HOW MUCH I GOT FROM  ./Data/RedTide_Sarasota_all_SIMPLE_columns.csv 9533\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        if filename.startswith('RedTide'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            data = pd.read_csv(file_path)\n",
    "    \n",
    "            total = + len(data)\n",
    "            labelled_accounts_df = pd.read_csv(\"Final_Account_Labels_for_Dashboard.csv\")\n",
    "            labelled_accounts_df = labelled_accounts_df[[\"Label\", \"username\"]]\n",
    "            labelled_accounts_df.rename(columns={'Label': 'label'}, inplace=True)\n",
    "            try:\n",
    "                # calculating the 'engagement' metric\n",
    "                engagement_columns = ['public_metrics.x_retweet_count', 'public_metrics.x_reply_count',\n",
    "                                      'public_metrics.x_like_count', 'public_metrics.x_quote_count',\n",
    "                                      'public_metrics.x_impression_count']\n",
    "                data['engagement'] = data[engagement_columns].sum(axis=1)\n",
    "    \n",
    "                selected_columns = ['text', 'username', 'created_at.x', 'profile_image_url', 'location','conversation_id', 'engagement']\n",
    "                data = data[selected_columns]\n",
    "                data.rename(columns={'created_at.x': 'time', 'profile_image_url': 'image', 'conversation_id':'id'}, inplace=True)\n",
    "                # Extract date part from the 'time' column\n",
    "                data['time'] = data['time'].str.split(' ').str[0].apply(convert_to_datetime)\n",
    "    \n",
    "                # Remove duplicates based on 'text' column\n",
    "                data.drop_duplicates(subset='text', keep='first', inplace=True)\n",
    "                \n",
    "                county_name = \"Hillsborough\"\n",
    "                # updating the location column with county name\n",
    "                if 'Pasco' in filename:\n",
    "                    data['location'] = 'Pasco'\n",
    "                    county_name = 'Pasco'\n",
    "                elif 'Pinellas' in filename:\n",
    "                    data['location'] = 'Pinellas'\n",
    "                    county_name = 'Pinellas'\n",
    "                elif 'Tampa' in filename:\n",
    "                    data['location'] = 'Hillsborough'\n",
    "                    county_name = 'Hillsborough'\n",
    "                elif 'Manatee' in filename:\n",
    "                    data['location'] = 'Manatee'\n",
    "                    county_name = 'Manatee'\n",
    "                elif 'Sarasota' in filename:\n",
    "                    data['location'] = 'Sarasota'\n",
    "                    county_name = 'Sarasota'\n",
    "    \n",
    "                # TODO: Add a account type column\n",
    "                data = pd.merge(data, labelled_accounts_df, on='username', how='left')\n",
    "                data.fillna('No Label', inplace=True)\n",
    "    \n",
    "                # Order the DataFrame based on 'engagement'\n",
    "                data = data.sort_values(by='engagement', ascending=False)\n",
    "    \n",
    "                # Take the top 200 tweets\n",
    "                top_100_tweets = data.head(10000)\n",
    "                print(\"HOW MUCH I GOT FROM \", file_path, len(top_100_tweets))\n",
    "    \n",
    "                data_frames.append(top_100_tweets)\n",
    "            except Exception as E:\n",
    "                print(\"ISSUE WITH THE FOLLOWING FILE:\", filename)\n",
    "                print(E)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T16:51:22.010864Z",
     "start_time": "2024-04-24T16:51:20.329432Z"
    }
   },
   "id": "95c3d8c370bbf02"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# data_frames[]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T16:51:38.256226Z",
     "start_time": "2024-04-24T16:51:38.251641Z"
    }
   },
   "id": "8c93a0d59d86322a"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "big_data_frame = pd.concat(data_frames, ignore_index=True)\n",
    "big_data_frame.drop_duplicates(subset='text', keep='first', inplace=True)\n",
    "big_data_frame.drop_duplicates(subset='id', keep='first', inplace=True)\n",
    "big_data_frame = big_data_frame.sample(frac=1).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T16:54:01.147361Z",
     "start_time": "2024-04-24T16:54:01.111455Z"
    }
   },
   "id": "eb690209e089fc59"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting Done. Successfully Inserted  20567 Tweets.\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "\n",
    "MONGO_URI = \"mongodb+srv://Neffati:y4m4SKKmoIg6riCP@cluster0.h1xa7vw.mongodb.net/?retryWrites=true&w=majority\"\n",
    "connection = pymongo.MongoClient(MONGO_URI)\n",
    "\n",
    "db = connection.tweets\n",
    "db[\"all_tweets\"].drop()    # Cleans out everything \n",
    "\n",
    "all_tweets = db.all_tweets # Makes a new collection \n",
    "all_tweets.insert_many(big_data_frame.to_dict('records'))\n",
    "\n",
    "print(\"Inserting Done. Successfully Inserted \", len(big_data_frame), \"Tweets.\")\n",
    "\n",
    "# output_csv_path = 'big_data.csv'\n",
    "# big_data_frame.to_csv(output_csv_path, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-24T16:54:06.289601Z",
     "start_time": "2024-04-24T16:54:01.687573Z"
    }
   },
   "id": "d1ef4ddc7710ffe6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fd81851a10e9e2de"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
