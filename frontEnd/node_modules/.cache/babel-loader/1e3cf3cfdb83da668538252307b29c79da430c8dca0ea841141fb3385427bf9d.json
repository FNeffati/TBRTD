{"ast":null,"code":"var _jsxFileName = \"/Users/fneffati/Documents/Classes/TBRTD/frontEnd/src/components/WordCloud.js\",\n  _s = $RefreshSig$();\nimport React, { useEffect, useMemo, useState } from \"react\";\nimport ReactWordcloud from \"react-wordcloud\";\nimport 'tippy.js/dist/tippy.css';\nimport Util from './analysis';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst WordCloud = ({\n  cloud_type,\n  tweets,\n  onWordCloudClick\n}) => {\n  _s();\n  const [words, setWords] = useState([{\n    text: \"LOADING\",\n    value: 20\n  }]);\n  const [loading, setLoading] = useState(false);\n  useEffect(() => {\n    console.log(cloud_type);\n    if (tweets.length > 0) {\n      if (cloud_type.length === 0) {\n        const top100Words = Util.regularWordCloud(tweets);\n        setWords(top100Words);\n      } else if (cloud_type[0] === \"Geo Hashtags\") {\n        console.log(\"HERE HERE\");\n        const hashtags = Util.hashtagsCloud(tweets);\n        setWords(hashtags);\n      }\n    } else {\n      setWords([{\n        text: \"LOADING\",\n        value: 20\n      }]);\n    }\n  }, [tweets, cloud_type]);\n\n  // function extractHashtags(sentence) {\n  //     const result = [];\n  //     for (const word of sentence) {\n  //         if (word[0] === '#' && !result.includes(word)) {\n  //             result.push(word);\n  //         }\n  //     }\n  //     return result;\n  // }\n  //\n  // function filterHashtags(tokenizedSentence) {\n  //     const result = [];\n  //     for (const w of tokenizedSentence) {\n  //         const hashtag = w;\n  //         const pureWord = hashtag.replace(/#/g, \"\").toLowerCase();\n  //         let approved = true;\n  //         const stopWords = getStopWords(true);\n  //\n  //         for (const word of stopWords) {\n  //             if (pureWord.includes(word.toLowerCase())) {\n  //                 approved = false;\n  //                 break;\n  //             }\n  //         }\n  //         if (approved) {\n  //             result.push(pureWord);\n  //         }\n  //     }\n  //     return result;\n  // }\n  //\n  // function geoTagHarvester(listOfHashtags) {\n  //     const pureSet = getCombinedLocations()\n  //     const paddedSet = categoryAdder();\n  //\n  //     for (const word of listOfHashtags) {\n  //         let caught = false;\n  //\n  //         for (const word2 of pureSet) {\n  //             if (word.includes(word2.toLowerCase()) || word2.toLowerCase().includes(word)) {\n  //                 geoTagDict[word] = (geoTagDict[word] || 0) + 1;\n  //                 caught = true;\n  //                 break;\n  //             }\n  //         }\n  //\n  //         if (!caught) {\n  //             for (const word2 of paddedSet) {\n  //                 if (word.includes(word2.toLowerCase())) {\n  //                     geoTagDict[word] = (geoTagDict[word] || 0) + 1;\n  //                     caught = true;\n  //                     break;\n  //                 }\n  //             }\n  //         }\n  //\n  //         if (!caught) {\n  //             nonGeoHashtagsDict[word] = (nonGeoHashtagsDict[word] || 0) + 1;\n  //         }\n  //     }\n  // }\n  //\n  //\n  // const fetchTerms = () => {\n  //     const justTextCol = [];\n  //     for (const line of tweets) {\n  //         // console.log(line['text'])\n  //         let modifiedLine = line['text'].replace(/\\bhttps\\w*\\b.*/, '');\n  //         modifiedLine = modifiedLine.replace(/\\bhttp\\w*\\b.*/, '');\n  //         justTextCol.push(modifiedLine);\n  //     }\n  //     // console.log(justTextCol)\n  //     const tokenizedTextColumn = [];\n  //     for (const line of justTextCol) {\n  //         const myPunct = ['!', '\"', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '-', '`', '{', '|', '}', '~', '»', '«', '“', '”'];\n  //\n  //         const punctPattern = new RegExp(\"[\" + myPunct.map(punct => \"\\\\\" + punct).join(\"\") + \"]\", \"g\");\n  //         let modifiedLine = line.replace(punctPattern, \"\");\n  //         modifiedLine = modifiedLine.replace(/[^\\w\\s'#]/g, \"\");\n  //         modifiedLine = modifiedLine.replace(/\\s+/g, \" \");\n  //         modifiedLine = modifiedLine.replace(/(https|www).*com/g, \"\");\n  //         modifiedLine = modifiedLine.trim();\n  //         const tokenizedText = modifiedLine.split(\" \");\n  //\n  //         if (!tokenizedTextColumn.some(existingText => JSON.stringify(existingText) === JSON.stringify(tokenizedText))) {\n  //             const hashtags = extractHashtags(tokenizedText);\n  //             const filteredTags = filterHashtags(hashtags);\n  //             geoTagHarvester(filteredTags);\n  //             tokenizedTextColumn.push(tokenizedText);\n  //         }\n  //     }\n  //\n  //     // console.log(tokenizedTextColumn)\n  //\n  //     let result = []\n  //     // if (cloud_type.includes('Non-Geo')) {\n  //         // result = Object.entries(nonGeoHashtagsDict).map(([key, value]) => ({ \"text\": key, \"value\": value }));\n  //     // } else if (cloud_type.includes('Geo')) {\n  //         // result = Object.entries(geoTagDict).map(([key, value]) => ({\"text\": key, \"value\": value}));\n  //     // }\n  //     // } else if (cloud_type.includes('Single')) {\n  //     //     result = getSingleTermWords();\n  //     // }\n  //     console.log(\"RESULT\")\n  //     console.log(nonGeoHashtagsDict)\n  //     return result\n  //\n  // }\n\n  const options = useMemo(() => ({\n    rotations: 1,\n    rotationAngles: [0],\n    fontSizes: [15, 60],\n    colors: [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\", \"#8c564b\"],\n    enableTooltip: true,\n    deterministic: true,\n    fontFamily: \"impact\",\n    fontStyle: \"normal\",\n    fontWeight: \"normal\",\n    padding: 1,\n    scale: \"sqrt\",\n    spiral: \"archimedean\",\n    transitionDuration: 1000\n  }), []);\n  const callbacks = useMemo(() => ({\n    onWordClick: word => onWordCloudClick('#' + word.text)\n  }), []);\n  const size = useMemo(() => [500, 600], []);\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"word-cloud-container\",\n    children: [/*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"loading\",\n      children: loading && /*#__PURE__*/_jsxDEV(\"p\", {\n        children: \"Loading...\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 177,\n        columnNumber: 50\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 177,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"word-cloud\",\n      children: /*#__PURE__*/_jsxDEV(ReactWordcloud, {\n        words: words,\n        options: options,\n        size: size,\n        padding: 0,\n        callbacks: callbacks\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 179,\n        columnNumber: 17\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 178,\n      columnNumber: 13\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 176,\n    columnNumber: 9\n  }, this);\n};\n_s(WordCloud, \"m5tUFdGo8ZvWTHPFI8fHSKoqoKQ=\");\n_c = WordCloud;\nexport default WordCloud;\nvar _c;\n$RefreshReg$(_c, \"WordCloud\");","map":{"version":3,"names":["React","useEffect","useMemo","useState","ReactWordcloud","Util","jsxDEV","_jsxDEV","WordCloud","cloud_type","tweets","onWordCloudClick","_s","words","setWords","text","value","loading","setLoading","console","log","length","top100Words","regularWordCloud","hashtags","hashtagsCloud","options","rotations","rotationAngles","fontSizes","colors","enableTooltip","deterministic","fontFamily","fontStyle","fontWeight","padding","scale","spiral","transitionDuration","callbacks","onWordClick","word","size","className","children","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["/Users/fneffati/Documents/Classes/TBRTD/frontEnd/src/components/WordCloud.js"],"sourcesContent":["import React, {useEffect, useMemo, useState} from \"react\";\nimport ReactWordcloud from \"react-wordcloud\";\nimport 'tippy.js/dist/tippy.css';\nimport Util from './analysis';\n\n\nconst WordCloud = ({ cloud_type, tweets, onWordCloudClick}) => {\n\n    const [words, setWords] = useState([{\n        text: \"LOADING\",\n        value: 20\n    }]);\n    const [loading, setLoading] = useState(false);\n\n\n    useEffect(() => {\n        console.log(cloud_type)\n        if (tweets.length > 0) {\n            if (cloud_type.length === 0) {\n                const top100Words = Util.regularWordCloud(tweets);\n                setWords(top100Words);\n            } else if (cloud_type[0] === \"Geo Hashtags\") {\n                console.log(\"HERE HERE\")\n                const hashtags = Util.hashtagsCloud(tweets);\n                setWords(hashtags);\n            }\n        } else {\n            setWords([{\n                text: \"LOADING\",\n                value: 20\n            }]);\n        }\n    }, [tweets, cloud_type]);\n\n    // function extractHashtags(sentence) {\n    //     const result = [];\n    //     for (const word of sentence) {\n    //         if (word[0] === '#' && !result.includes(word)) {\n    //             result.push(word);\n    //         }\n    //     }\n    //     return result;\n    // }\n    //\n    // function filterHashtags(tokenizedSentence) {\n    //     const result = [];\n    //     for (const w of tokenizedSentence) {\n    //         const hashtag = w;\n    //         const pureWord = hashtag.replace(/#/g, \"\").toLowerCase();\n    //         let approved = true;\n    //         const stopWords = getStopWords(true);\n    //\n    //         for (const word of stopWords) {\n    //             if (pureWord.includes(word.toLowerCase())) {\n    //                 approved = false;\n    //                 break;\n    //             }\n    //         }\n    //         if (approved) {\n    //             result.push(pureWord);\n    //         }\n    //     }\n    //     return result;\n    // }\n    //\n    // function geoTagHarvester(listOfHashtags) {\n    //     const pureSet = getCombinedLocations()\n    //     const paddedSet = categoryAdder();\n    //\n    //     for (const word of listOfHashtags) {\n    //         let caught = false;\n    //\n    //         for (const word2 of pureSet) {\n    //             if (word.includes(word2.toLowerCase()) || word2.toLowerCase().includes(word)) {\n    //                 geoTagDict[word] = (geoTagDict[word] || 0) + 1;\n    //                 caught = true;\n    //                 break;\n    //             }\n    //         }\n    //\n    //         if (!caught) {\n    //             for (const word2 of paddedSet) {\n    //                 if (word.includes(word2.toLowerCase())) {\n    //                     geoTagDict[word] = (geoTagDict[word] || 0) + 1;\n    //                     caught = true;\n    //                     break;\n    //                 }\n    //             }\n    //         }\n    //\n    //         if (!caught) {\n    //             nonGeoHashtagsDict[word] = (nonGeoHashtagsDict[word] || 0) + 1;\n    //         }\n    //     }\n    // }\n    //\n    //\n    // const fetchTerms = () => {\n    //     const justTextCol = [];\n    //     for (const line of tweets) {\n    //         // console.log(line['text'])\n    //         let modifiedLine = line['text'].replace(/\\bhttps\\w*\\b.*/, '');\n    //         modifiedLine = modifiedLine.replace(/\\bhttp\\w*\\b.*/, '');\n    //         justTextCol.push(modifiedLine);\n    //     }\n    //     // console.log(justTextCol)\n    //     const tokenizedTextColumn = [];\n    //     for (const line of justTextCol) {\n    //         const myPunct = ['!', '\"', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '-', '`', '{', '|', '}', '~', '»', '«', '“', '”'];\n    //\n    //         const punctPattern = new RegExp(\"[\" + myPunct.map(punct => \"\\\\\" + punct).join(\"\") + \"]\", \"g\");\n    //         let modifiedLine = line.replace(punctPattern, \"\");\n    //         modifiedLine = modifiedLine.replace(/[^\\w\\s'#]/g, \"\");\n    //         modifiedLine = modifiedLine.replace(/\\s+/g, \" \");\n    //         modifiedLine = modifiedLine.replace(/(https|www).*com/g, \"\");\n    //         modifiedLine = modifiedLine.trim();\n    //         const tokenizedText = modifiedLine.split(\" \");\n    //\n    //         if (!tokenizedTextColumn.some(existingText => JSON.stringify(existingText) === JSON.stringify(tokenizedText))) {\n    //             const hashtags = extractHashtags(tokenizedText);\n    //             const filteredTags = filterHashtags(hashtags);\n    //             geoTagHarvester(filteredTags);\n    //             tokenizedTextColumn.push(tokenizedText);\n    //         }\n    //     }\n    //\n    //     // console.log(tokenizedTextColumn)\n    //\n    //     let result = []\n    //     // if (cloud_type.includes('Non-Geo')) {\n    //         // result = Object.entries(nonGeoHashtagsDict).map(([key, value]) => ({ \"text\": key, \"value\": value }));\n    //     // } else if (cloud_type.includes('Geo')) {\n    //         // result = Object.entries(geoTagDict).map(([key, value]) => ({\"text\": key, \"value\": value}));\n    //     // }\n    //     // } else if (cloud_type.includes('Single')) {\n    //     //     result = getSingleTermWords();\n    //     // }\n    //     console.log(\"RESULT\")\n    //     console.log(nonGeoHashtagsDict)\n    //     return result\n    //\n    // }\n\n\n\n\n    const options = useMemo(\n        () => ({\n            rotations: 1,\n            rotationAngles: [0],\n            fontSizes: [15, 60],\n            colors: [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\", \"#8c564b\"],\n            enableTooltip: true,\n            deterministic: true,\n            fontFamily: \"impact\",\n            fontStyle: \"normal\",\n            fontWeight: \"normal\",\n            padding: 1,\n            scale: \"sqrt\",\n            spiral: \"archimedean\",\n            transitionDuration: 1000,\n        }),\n        []\n    );\n\n    const callbacks = useMemo(\n        () => ({\n            onWordClick: (word) => onWordCloudClick('#'+word.text)\n        }),\n        []\n    );\n\n    const size = useMemo(() => [500, 600], []);\n\n    return (\n        <div className=\"word-cloud-container\">\n            <div className=\"loading\">{loading && <p>Loading...</p>}</div>\n            <div className=\"word-cloud\">\n                <ReactWordcloud  words={words} options={options} size={size} padding={0} callbacks={callbacks}/>\n            </div>\n        </div>\n    );\n};\n\nexport default WordCloud;"],"mappings":";;AAAA,OAAOA,KAAK,IAAGC,SAAS,EAAEC,OAAO,EAAEC,QAAQ,QAAO,OAAO;AACzD,OAAOC,cAAc,MAAM,iBAAiB;AAC5C,OAAO,yBAAyB;AAChC,OAAOC,IAAI,MAAM,YAAY;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAG9B,MAAMC,SAAS,GAAGA,CAAC;EAAEC,UAAU;EAAEC,MAAM;EAAEC;AAAgB,CAAC,KAAK;EAAAC,EAAA;EAE3D,MAAM,CAACC,KAAK,EAAEC,QAAQ,CAAC,GAAGX,QAAQ,CAAC,CAAC;IAChCY,IAAI,EAAE,SAAS;IACfC,KAAK,EAAE;EACX,CAAC,CAAC,CAAC;EACH,MAAM,CAACC,OAAO,EAAEC,UAAU,CAAC,GAAGf,QAAQ,CAAC,KAAK,CAAC;EAG7CF,SAAS,CAAC,MAAM;IACZkB,OAAO,CAACC,GAAG,CAACX,UAAU,CAAC;IACvB,IAAIC,MAAM,CAACW,MAAM,GAAG,CAAC,EAAE;MACnB,IAAIZ,UAAU,CAACY,MAAM,KAAK,CAAC,EAAE;QACzB,MAAMC,WAAW,GAAGjB,IAAI,CAACkB,gBAAgB,CAACb,MAAM,CAAC;QACjDI,QAAQ,CAACQ,WAAW,CAAC;MACzB,CAAC,MAAM,IAAIb,UAAU,CAAC,CAAC,CAAC,KAAK,cAAc,EAAE;QACzCU,OAAO,CAACC,GAAG,CAAC,WAAW,CAAC;QACxB,MAAMI,QAAQ,GAAGnB,IAAI,CAACoB,aAAa,CAACf,MAAM,CAAC;QAC3CI,QAAQ,CAACU,QAAQ,CAAC;MACtB;IACJ,CAAC,MAAM;MACHV,QAAQ,CAAC,CAAC;QACNC,IAAI,EAAE,SAAS;QACfC,KAAK,EAAE;MACX,CAAC,CAAC,CAAC;IACP;EACJ,CAAC,EAAE,CAACN,MAAM,EAAED,UAAU,CAAC,CAAC;;EAExB;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;;EAKA,MAAMiB,OAAO,GAAGxB,OAAO,CACnB,OAAO;IACHyB,SAAS,EAAE,CAAC;IACZC,cAAc,EAAE,CAAC,CAAC,CAAC;IACnBC,SAAS,EAAE,CAAC,EAAE,EAAE,EAAE,CAAC;IACnBC,MAAM,EAAE,CAAC,SAAS,EAAE,SAAS,EAAE,SAAS,EAAE,SAAS,EAAE,SAAS,EAAE,SAAS,CAAC;IAC1EC,aAAa,EAAE,IAAI;IACnBC,aAAa,EAAE,IAAI;IACnBC,UAAU,EAAE,QAAQ;IACpBC,SAAS,EAAE,QAAQ;IACnBC,UAAU,EAAE,QAAQ;IACpBC,OAAO,EAAE,CAAC;IACVC,KAAK,EAAE,MAAM;IACbC,MAAM,EAAE,aAAa;IACrBC,kBAAkB,EAAE;EACxB,CAAC,CAAC,EACF,EACJ,CAAC;EAED,MAAMC,SAAS,GAAGtC,OAAO,CACrB,OAAO;IACHuC,WAAW,EAAGC,IAAI,IAAK/B,gBAAgB,CAAC,GAAG,GAAC+B,IAAI,CAAC3B,IAAI;EACzD,CAAC,CAAC,EACF,EACJ,CAAC;EAED,MAAM4B,IAAI,GAAGzC,OAAO,CAAC,MAAM,CAAC,GAAG,EAAE,GAAG,CAAC,EAAE,EAAE,CAAC;EAE1C,oBACIK,OAAA;IAAKqC,SAAS,EAAC,sBAAsB;IAAAC,QAAA,gBACjCtC,OAAA;MAAKqC,SAAS,EAAC,SAAS;MAAAC,QAAA,EAAE5B,OAAO,iBAAIV,OAAA;QAAAsC,QAAA,EAAG;MAAU;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAG;IAAC;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAM,CAAC,eAC7D1C,OAAA;MAAKqC,SAAS,EAAC,YAAY;MAAAC,QAAA,eACvBtC,OAAA,CAACH,cAAc;QAAES,KAAK,EAAEA,KAAM;QAACa,OAAO,EAAEA,OAAQ;QAACiB,IAAI,EAAEA,IAAK;QAACP,OAAO,EAAE,CAAE;QAACI,SAAS,EAAEA;MAAU;QAAAM,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAC;IAAC;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAC/F,CAAC;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACL,CAAC;AAEd,CAAC;AAACrC,EAAA,CAhLIJ,SAAS;AAAA0C,EAAA,GAAT1C,SAAS;AAkLf,eAAeA,SAAS;AAAC,IAAA0C,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}